{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c8f338-1038-4be7-9c35-7d8f62bb51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Lambda\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from torchvision.models.resnet import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab3b1eb9-6dd5-474a-94bb-f4112ab4efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.dirname(os.path.abspath('.'))\n",
    "sys.path.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d805b0d-9619-42ec-b52b-0d1838256c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\negra\\\\mymlprojects\\\\cifar10'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d69ae0-a0d8-412b-b125-5b41f4a5fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CIFAR10dataset import CIFAR10dataset\n",
    "from src.SmallCNN import SmallCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5ac5c1-08f1-4f8c-ae93-45b3e09a21f1",
   "metadata": {},
   "source": [
    "## DEFINE IMAGE TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e927750a-2f74-482d-b641-9c4f36699416",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_mean = [0.4914,0.4822,0.4465]\n",
    "cifar_stdev = [0.2470,0.2435,0.2616]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c4f38e8-e75b-40ce-b364-7e776d37b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(),transforms.Normalize(cifar_mean,cifar_stdev)])\n",
    "tgt_tf = Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789f2164-3eab-409d-bb83-f36a9560505a",
   "metadata": {},
   "source": [
    "## LOAD CIFAR10 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a961a9f3-e3e8-477b-8018-89b161e9c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_ds = CIFAR10dataset(root='../data',train=True,transform=tf,target_transform = tgt_tf)\n",
    "test_ds = CIFAR10dataset(root='../data',train=False,transform=tf,target_transform=tgt_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15b24909-ed11-44af-9b01-a84dae116cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1 = torch.Generator().manual_seed(1)\n",
    "train_frac = 0.9\n",
    "val_frac = 1 - train_frac\n",
    "train_ds, val_ds = torch.utils.data.random_split(train_val_ds,[train_frac,val_frac],generator=gen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c5ea52e-584e-4317-8b16-c24ce9f3e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds,batch_size=64,shuffle=False)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68dc93fd-df51-4df0-9c5d-bd6e5e80c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(im):\n",
    "    stdev = torch.tensor(cifar_stdev)\n",
    "    stdev = stdev.reshape((3,1,1))\n",
    "    mean = torch.tensor(cifar_mean)\n",
    "    mean = mean.reshape((3,1,1))\n",
    "    im = im*stdev+mean\n",
    "    im = torch.permute(im,(1,2,0))\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32e11562-3244-4878-9075-bcb95694eb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im1,label = next(iter(train_dl))\n",
    "show_image(im1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5016a207-5b04-4bf0-acbf-57f72489ef82",
   "metadata": {},
   "source": [
    "## DEFINE MODEL, OPTIMIZER, LOSS FUNCTION, DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09b9d9d8-1fdd-41fe-9596-c6e8329afbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "mo1 = SmallCNN().to(device)\n",
    "opt1 = optim.SGD(mo1.parameters(),lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00c95980-2c02-4f02-a8e0-3e64acea41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137a84d0-8a06-4243-87b8-42f4114e6606",
   "metadata": {},
   "source": [
    "## DEFINE TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cea9c0a-ff69-405b-b8f9-5971869ac519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:50: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:50: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\negra\\AppData\\Local\\Temp\\ipykernel_23604\\3657586241.py:50: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  f'..\\models\\cifar_model_v1_it{e}.pt')\n"
     ]
    }
   ],
   "source": [
    "def train_model(model,train_data,val_data,optimizer,loss_fn,epochs=1):\n",
    "    n_train_samples = len(train_data.dataset.indices)\n",
    "    n_val_samples = len(val_data.dataset.indices)\n",
    "    best_acc = 0\n",
    "    for e in range(1,epochs+1):\n",
    "        model.train()\n",
    "        cum_train_loss = 0\n",
    "        cum_val_loss = 0\n",
    "        train_acc = 0\n",
    "        val_acc = 0\n",
    "        for i,(example,label) in enumerate(train_data):\n",
    "            example = example.to(device)\n",
    "            label = label.to(device)\n",
    "            vals,lbl_classes = label.max(dim=1)\n",
    "            pred = model(example)\n",
    "            vals, prd_classes = pred.max(dim=1)\n",
    "            loss = loss_fn(pred,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            cum_train_loss += loss/n_train_samples\n",
    "            train_acc += sum(lbl_classes == prd_classes)\n",
    "            if i % 100 == 0:\n",
    "                print(f'Cumulative train loss = {cum_train_loss}, Batch = {i}')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i,(example,label) in enumerate(val_data):\n",
    "                example = example.to(device)\n",
    "                label = label.to(device)\n",
    "                vals,lbl_classes = label.max(dim=1)\n",
    "                pred = model(example)\n",
    "                vals,prd_classes = pred.max(dim=1)\n",
    "                loss = loss_fn(pred,label)\n",
    "                cum_val_loss += loss/n_val_samples\n",
    "                val_acc += sum(lbl_classes == prd_classes)\n",
    "                if i % 100 == 0:\n",
    "                    print(f'Cumulative validation loss = {cum_val_loss}, Batch = {i}')\n",
    "            train_acc = train_acc/n_train_samples\n",
    "            val_acc = val_acc/n_val_samples\n",
    "            info_str = f'Epoch {e} train/val loss: {cum_train_loss:.4f}/{cum_val_loss:.4f} \\n train/val accuracy: {train_acc:.4f}/{val_acc:.4f}'\n",
    "            print(info_str)\n",
    "            print('\\n')\n",
    "            if val_acc > best_acc + 0.01:\n",
    "                best_acc = val_acc\n",
    "                torch.save({'epoch': e,\n",
    "                            'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict':optimizer.state_dict(),\n",
    "                            'loss':cum_val_loss,\n",
    "                            'acc':val_acc},\n",
    "                           f'..\\models\\cifar_model_v1_it{e}.pt')\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773c24dc-4da2-4839-a355-e7a7b0db52d6",
   "metadata": {},
   "source": [
    "## TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "794ca035-09e7-4224-b967-1dc00a204d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative train loss = 5.2288523875176907e-05, Batch = 0\n",
      "Cumulative train loss = 0.005016714334487915, Batch = 100\n",
      "Cumulative train loss = 0.009655636735260487, Batch = 200\n",
      "Cumulative train loss = 0.01410465594381094, Batch = 300\n",
      "Cumulative train loss = 0.018401095643639565, Batch = 400\n",
      "Cumulative train loss = 0.022577278316020966, Batch = 500\n",
      "Cumulative train loss = 0.026620281860232353, Batch = 600\n",
      "Cumulative train loss = 0.030592037364840508, Batch = 700\n",
      "Cumulative validation loss = 0.000372387352399528, Batch = 0\n",
      "Epoch 1 train/val loss: 0.0307/0.0296 \n",
      " train/val accuracy: 0.3171/0.3257\n",
      "\n",
      "\n",
      "Cumulative train loss = 3.834317612927407e-05, Batch = 0\n",
      "Cumulative train loss = 0.003901868360117078, Batch = 100\n",
      "Cumulative train loss = 0.007683132775127888, Batch = 200\n",
      "Cumulative train loss = 0.011374392546713352, Batch = 300\n",
      "Cumulative train loss = 0.015043859370052814, Batch = 400\n",
      "Cumulative train loss = 0.018628666177392006, Batch = 500\n",
      "Cumulative train loss = 0.02218238264322281, Batch = 600\n",
      "Cumulative train loss = 0.02565988153219223, Batch = 700\n",
      "Cumulative validation loss = 0.00032971976906992495, Batch = 0\n",
      "Epoch 2 train/val loss: 0.0258/0.0261 \n",
      " train/val accuracy: 0.4289/0.4109\n",
      "\n",
      "\n",
      "Cumulative train loss = 3.592339271563105e-05, Batch = 0\n",
      "Cumulative train loss = 0.003471420146524906, Batch = 100\n",
      "Cumulative train loss = 0.0068456875160336494, Batch = 200\n",
      "Cumulative train loss = 0.010187014937400818, Batch = 300\n",
      "Cumulative train loss = 0.013541043736040592, Batch = 400\n",
      "Cumulative train loss = 0.016835248097777367, Batch = 500\n",
      "Cumulative train loss = 0.020122215151786804, Batch = 600\n",
      "Cumulative train loss = 0.023327674716711044, Batch = 700\n",
      "Cumulative validation loss = 0.0002907909220084548, Batch = 0\n",
      "Epoch 3 train/val loss: 0.0234/0.0235 \n",
      " train/val accuracy: 0.4717/0.4669\n",
      "\n",
      "\n",
      "Cumulative train loss = 3.350804399815388e-05, Batch = 0\n",
      "Cumulative train loss = 0.003247817512601614, Batch = 100\n",
      "Cumulative train loss = 0.006397823337465525, Batch = 200\n",
      "Cumulative train loss = 0.0095484284684062, Batch = 300\n",
      "Cumulative train loss = 0.012687692418694496, Batch = 400\n",
      "Cumulative train loss = 0.015786347910761833, Batch = 500\n",
      "Cumulative train loss = 0.018874123692512512, Batch = 600\n",
      "Cumulative train loss = 0.021885842084884644, Batch = 700\n",
      "Cumulative validation loss = 0.0002801365917548537, Batch = 0\n",
      "Epoch 4 train/val loss: 0.0220/0.0221 \n",
      " train/val accuracy: 0.5015/0.4933\n",
      "\n",
      "\n",
      "Cumulative train loss = 3.024543184437789e-05, Batch = 0\n",
      "Cumulative train loss = 0.003040276002138853, Batch = 100\n",
      "Cumulative train loss = 0.006043773610144854, Batch = 200\n",
      "Cumulative train loss = 0.009000403806567192, Batch = 300\n",
      "Cumulative train loss = 0.011983474716544151, Batch = 400\n",
      "Cumulative train loss = 0.014922439120709896, Batch = 500\n",
      "Cumulative train loss = 0.017821433022618294, Batch = 600\n",
      "Cumulative train loss = 0.02075927145779133, Batch = 700\n",
      "Cumulative validation loss = 0.00027950952062383294, Batch = 0\n",
      "Epoch 5 train/val loss: 0.0209/0.0229 \n",
      " train/val accuracy: 0.5274/0.4833\n",
      "\n",
      "\n",
      "Cumulative train loss = 2.511251477699261e-05, Batch = 0\n",
      "Cumulative train loss = 0.00290687452070415, Batch = 100\n",
      "Cumulative train loss = 0.005761869251728058, Batch = 200\n",
      "Cumulative train loss = 0.008605984039604664, Batch = 300\n",
      "Cumulative train loss = 0.011466271243989468, Batch = 400\n",
      "Cumulative train loss = 0.014293386600911617, Batch = 500\n",
      "Cumulative train loss = 0.01711929962038994, Batch = 600\n",
      "Cumulative train loss = 0.01993168517947197, Batch = 700\n",
      "Cumulative validation loss = 0.000265650189248845, Batch = 0\n",
      "Epoch 6 train/val loss: 0.0200/0.0211 \n",
      " train/val accuracy: 0.5449/0.5225\n",
      "\n",
      "\n",
      "Cumulative train loss = 2.8991526050958782e-05, Batch = 0\n",
      "Cumulative train loss = 0.0027174046263098717, Batch = 100\n",
      "Cumulative train loss = 0.005494686309248209, Batch = 200\n",
      "Cumulative train loss = 0.008282262831926346, Batch = 300\n",
      "Cumulative train loss = 0.011045734398066998, Batch = 400\n",
      "Cumulative train loss = 0.013804219663143158, Batch = 500\n",
      "Cumulative train loss = 0.016537198796868324, Batch = 600\n",
      "Cumulative train loss = 0.019230026751756668, Batch = 700\n",
      "Cumulative validation loss = 0.0002606195048429072, Batch = 0\n",
      "Epoch 7 train/val loss: 0.0193/0.0219 \n",
      " train/val accuracy: 0.5629/0.5141\n",
      "\n",
      "\n",
      "Cumulative train loss = 2.4404693249380216e-05, Batch = 0\n",
      "Cumulative train loss = 0.0026941290125250816, Batch = 100\n",
      "Cumulative train loss = 0.005364914424717426, Batch = 200\n",
      "Cumulative train loss = 0.00802603643387556, Batch = 300\n",
      "Cumulative train loss = 0.010650962591171265, Batch = 400\n",
      "Cumulative train loss = 0.013261057436466217, Batch = 500\n",
      "Cumulative train loss = 0.015882400795817375, Batch = 600\n",
      "Cumulative train loss = 0.01854165829718113, Batch = 700\n",
      "Cumulative validation loss = 0.0002592455130070448, Batch = 0\n",
      "Epoch 8 train/val loss: 0.0186/0.0202 \n",
      " train/val accuracy: 0.5778/0.5381\n",
      "\n",
      "\n",
      "Cumulative train loss = 2.8684054996119812e-05, Batch = 0\n",
      "Cumulative train loss = 0.0026240264996886253, Batch = 100\n",
      "Cumulative train loss = 0.00517304940149188, Batch = 200\n",
      "Cumulative train loss = 0.007765526417642832, Batch = 300\n",
      "Cumulative train loss = 0.010343176312744617, Batch = 400\n",
      "Cumulative train loss = 0.012881483882665634, Batch = 500\n",
      "Cumulative train loss = 0.01544972788542509, Batch = 600\n",
      "Cumulative train loss = 0.01801213063299656, Batch = 700\n",
      "Cumulative validation loss = 0.0002413706824881956, Batch = 0\n",
      "Epoch 9 train/val loss: 0.0181/0.0197 \n",
      " train/val accuracy: 0.5902/0.5541\n",
      "\n",
      "\n",
      "Cumulative train loss = 2.3493021217291243e-05, Batch = 0\n",
      "Cumulative train loss = 0.0025094137527048588, Batch = 100\n",
      "Cumulative train loss = 0.004982383456081152, Batch = 200\n",
      "Cumulative train loss = 0.007490586489439011, Batch = 300\n",
      "Cumulative train loss = 0.009972672909498215, Batch = 400\n",
      "Cumulative train loss = 0.012417342513799667, Batch = 500\n",
      "Cumulative train loss = 0.014898591674864292, Batch = 600\n",
      "Cumulative train loss = 0.017430253326892853, Batch = 700\n",
      "Cumulative validation loss = 0.0002453064080327749, Batch = 0\n",
      "Epoch 10 train/val loss: 0.0175/0.0192 \n",
      " train/val accuracy: 0.6041/0.5717\n",
      "\n",
      "\n",
      "Cumulative train loss = 2.3520067770732567e-05, Batch = 0\n",
      "Cumulative train loss = 0.0024987091310322285, Batch = 100\n",
      "Cumulative train loss = 0.004899631720036268, Batch = 200\n",
      "Cumulative train loss = 0.0073477462865412235, Batch = 300\n",
      "Cumulative train loss = 0.00976417027413845, Batch = 400\n",
      "Cumulative train loss = 0.012154454365372658, Batch = 500\n",
      "Cumulative train loss = 0.014552464708685875, Batch = 600\n",
      "Cumulative train loss = 0.016979843378067017, Batch = 700\n",
      "Cumulative validation loss = 0.0002704806684050709, Batch = 0\n",
      "Epoch 11 train/val loss: 0.0171/0.0206 \n",
      " train/val accuracy: 0.6155/0.5451\n",
      "\n",
      "\n",
      "Cumulative train loss = 1.9770524886553176e-05, Batch = 0\n",
      "Cumulative train loss = 0.0023555774241685867, Batch = 100\n",
      "Cumulative train loss = 0.004728134721517563, Batch = 200\n",
      "Cumulative train loss = 0.007154553197324276, Batch = 300\n",
      "Cumulative train loss = 0.009529884904623032, Batch = 400\n",
      "Cumulative train loss = 0.011848844587802887, Batch = 500\n",
      "Cumulative train loss = 0.014210941269993782, Batch = 600\n",
      "Cumulative train loss = 0.016590813174843788, Batch = 700\n",
      "Cumulative validation loss = 0.00021221641509328038, Batch = 0\n",
      "Epoch 12 train/val loss: 0.0167/0.0186 \n",
      " train/val accuracy: 0.6247/0.5901\n",
      "\n",
      "\n",
      "Cumulative train loss = 2.0291112377890386e-05, Batch = 0\n",
      "Cumulative train loss = 0.002341816434636712, Batch = 100\n",
      "Cumulative train loss = 0.004647314082831144, Batch = 200\n",
      "Cumulative train loss = 0.00695180194452405, Batch = 300\n",
      "Cumulative train loss = 0.009230036288499832, Batch = 400\n",
      "Cumulative train loss = 0.011544025503098965, Batch = 500\n",
      "Cumulative train loss = 0.013857443816959858, Batch = 600\n",
      "Cumulative train loss = 0.016177447512745857, Batch = 700\n",
      "Cumulative validation loss = 0.0002267322997795418, Batch = 0\n",
      "Epoch 13 train/val loss: 0.0162/0.0203 \n",
      " train/val accuracy: 0.6363/0.5635\n",
      "\n",
      "\n",
      "Cumulative train loss = 2.408712862234097e-05, Batch = 0\n",
      "Cumulative train loss = 0.0023046419955790043, Batch = 100\n",
      "Cumulative train loss = 0.004546991549432278, Batch = 200\n",
      "Cumulative train loss = 0.006782033480703831, Batch = 300\n",
      "Cumulative train loss = 0.009077329188585281, Batch = 400\n",
      "Cumulative train loss = 0.011379582807421684, Batch = 500\n",
      "Cumulative train loss = 0.013616575859487057, Batch = 600\n",
      "Cumulative train loss = 0.01583516225218773, Batch = 700\n",
      "Cumulative validation loss = 0.0002567298070061952, Batch = 0\n",
      "Epoch 14 train/val loss: 0.0159/0.0200 \n",
      " train/val accuracy: 0.6437/0.5651\n",
      "\n",
      "\n",
      "Cumulative train loss = 2.3358063117484562e-05, Batch = 0\n",
      "Cumulative train loss = 0.0022073036525398493, Batch = 100\n",
      "Cumulative train loss = 0.004431916866451502, Batch = 200\n",
      "Cumulative train loss = 0.006638001184910536, Batch = 300\n",
      "Cumulative train loss = 0.008878500200808048, Batch = 400\n",
      "Cumulative train loss = 0.011110636405646801, Batch = 500\n",
      "Cumulative train loss = 0.013294506818056107, Batch = 600\n",
      "Cumulative train loss = 0.015551079995930195, Batch = 700\n",
      "Cumulative validation loss = 0.00021532221580855548, Batch = 0\n",
      "Epoch 15 train/val loss: 0.0156/0.0179 \n",
      " train/val accuracy: 0.6480/0.5961\n",
      "\n",
      "\n",
      "Cumulative train loss = 2.1988924345350824e-05, Batch = 0\n",
      "Cumulative train loss = 0.0022006365470588207, Batch = 100\n",
      "Cumulative train loss = 0.004366795998066664, Batch = 200\n",
      "Cumulative train loss = 0.00646499078720808, Batch = 300\n",
      "Cumulative train loss = 0.008680025115609169, Batch = 400\n",
      "Cumulative train loss = 0.010872150771319866, Batch = 500\n",
      "Cumulative train loss = 0.013073863461613655, Batch = 600\n",
      "Cumulative train loss = 0.015218270011246204, Batch = 700\n",
      "Cumulative validation loss = 0.0002248830714961514, Batch = 0\n",
      "Epoch 16 train/val loss: 0.0153/0.0178 \n",
      " train/val accuracy: 0.6563/0.5925\n",
      "\n",
      "\n",
      "Cumulative train loss = 1.9306668036733754e-05, Batch = 0\n",
      "Cumulative train loss = 0.0021229698322713375, Batch = 100\n",
      "Cumulative train loss = 0.004217218607664108, Batch = 200\n",
      "Cumulative train loss = 0.006358431652188301, Batch = 300\n",
      "Cumulative train loss = 0.008465594612061977, Batch = 400\n",
      "Cumulative train loss = 0.01060490682721138, Batch = 500\n",
      "Cumulative train loss = 0.012743688188493252, Batch = 600\n",
      "Cumulative train loss = 0.014917807653546333, Batch = 700\n",
      "Cumulative validation loss = 0.00021306145936250687, Batch = 0\n",
      "Epoch 17 train/val loss: 0.0150/0.0200 \n",
      " train/val accuracy: 0.6632/0.5729\n",
      "\n",
      "\n",
      "Cumulative train loss = 2.6532621632213704e-05, Batch = 0\n",
      "Cumulative train loss = 0.0021490254439413548, Batch = 100\n",
      "Cumulative train loss = 0.004243727307766676, Batch = 200\n",
      "Cumulative train loss = 0.006315285339951515, Batch = 300\n",
      "Cumulative train loss = 0.008394117467105389, Batch = 400\n",
      "Cumulative train loss = 0.010485044680535793, Batch = 500\n",
      "Cumulative train loss = 0.012590189464390278, Batch = 600\n",
      "Cumulative train loss = 0.01472482644021511, Batch = 700\n",
      "Cumulative validation loss = 0.00022407346114050597, Batch = 0\n",
      "Epoch 18 train/val loss: 0.0148/0.0183 \n",
      " train/val accuracy: 0.6683/0.5929\n",
      "\n",
      "\n",
      "Cumulative train loss = 2.0582690922310576e-05, Batch = 0\n",
      "Cumulative train loss = 0.0020909758750349283, Batch = 100\n",
      "Cumulative train loss = 0.004141923971474171, Batch = 200\n",
      "Cumulative train loss = 0.0061927358619868755, Batch = 300\n",
      "Cumulative train loss = 0.008249929174780846, Batch = 400\n",
      "Cumulative train loss = 0.010261638090014458, Batch = 500\n",
      "Cumulative train loss = 0.012380123138427734, Batch = 600\n",
      "Cumulative train loss = 0.014426193200051785, Batch = 700\n",
      "Cumulative validation loss = 0.00020278645388316363, Batch = 0\n",
      "Epoch 19 train/val loss: 0.0145/0.0178 \n",
      " train/val accuracy: 0.6765/0.6037\n",
      "\n",
      "\n",
      "Cumulative train loss = 2.0784202206414193e-05, Batch = 0\n",
      "Cumulative train loss = 0.002013305202126503, Batch = 100\n",
      "Cumulative train loss = 0.003996945917606354, Batch = 200\n",
      "Cumulative train loss = 0.006023061461746693, Batch = 300\n",
      "Cumulative train loss = 0.008062039501965046, Batch = 400\n",
      "Cumulative train loss = 0.010137218981981277, Batch = 500\n",
      "Cumulative train loss = 0.012180875986814499, Batch = 600\n",
      "Cumulative train loss = 0.014256580732762814, Batch = 700\n",
      "Cumulative validation loss = 0.00021609838586300611, Batch = 0\n",
      "Epoch 20 train/val loss: 0.0143/0.0175 \n",
      " train/val accuracy: 0.6789/0.6065\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(mo1,train_dl,val_dl,opt1,loss_fn,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d563c82-515a-4fe6-95c6-558917367ee3",
   "metadata": {},
   "source": [
    "## LOAD PRETRAINED RESNET50 NN AND TUNE TO CIFAR10 CLASSIFICATION TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a0a216-0bdc-442f-a780-d7a4d26b5445",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_mo = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b65db7-a6dd-4d17-b7a4-2fb54ef57a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ref_mo.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9fc22-1da2-4cd6-9881-9157f6d6d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_mo.fc = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2),\n",
    "    torch.nn.Linear(in_features=2048,out_features=512,bias=True),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=512,out_features=32,bias=True),\n",
    "    torch.nn.BatchNorm1d(32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=32,out_features=10,bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419181a-73d2-4df4-b8a3-b2fc2d438760",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_mo = ref_mo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044dcecd-e809-41f0-87d3-6b0f9e323e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_opt = torch.optim.SGD(ref_mo.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64a40c5-e156-43bc-9d78-b5cc28b6f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a887712-9319-45d3-bf4e-561143aa198f",
   "metadata": {},
   "source": [
    "## TRAIN RESNET50 OUTPUT LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800b400-6d95-45fd-be2b-420f1cd06de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(ref_mo,train_dl,val_dl,ref_opt,ref_loss,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30d542-c9a7-4170-a953-ec21876512c9",
   "metadata": {},
   "source": [
    "## DEFINE EVALUATION LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e00e23b9-5cd1-4d84-809e-034fb1f43de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model,test_data,loss_fn):\n",
    "    model.eval()\n",
    "    cum_test_loss = 0\n",
    "    test_acc = 0\n",
    "    n_samples = len(test_data.dataset)\n",
    "    with torch.no_grad():\n",
    "        for i,(example,label) in enumerate(test_data):\n",
    "            example = example.to(device)\n",
    "            label = label.to(device)\n",
    "            pred = model(example)\n",
    "            loss = loss_fn(pred,label)\n",
    "            cum_test_loss += loss\n",
    "            vals,lbl_classes = label.max(dim=1)\n",
    "            vals,pred_classes = pred.max(dim=1)\n",
    "            test_acc += sum(pred_classes==lbl_classes)\n",
    "        cum_test_loss = cum_test_loss/n_samples\n",
    "        test_acc = test_acc/n_samples\n",
    "        info_str = f'Test loss: {cum_test_loss:.4f} \\n test accuracy: {test_acc:.4f}'\n",
    "        print(info_str)\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae4bb7-7ee4-4d45-b9a2-469bf5af52e4",
   "metadata": {},
   "source": [
    "## EVALUATE MODEL PERFORMANCE ON TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df9b1370-7bf2-41a8-a92b-7c8043c86ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0177 \n",
      " test accuracy: 0.6141\n"
     ]
    }
   ],
   "source": [
    "eval_model(mo1,test_dl,loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7f9b4-e724-4490-bba7-a8289be91596",
   "metadata": {},
   "source": [
    "## LOAD BEST MODEL AND SAVE WITH PICKLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adeaf3e0-15b9-4ebd-8b75-13892ef6dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = SmallCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91562e33-1f5f-4642-be38-5442065b410c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\negra\\AppData\\Local\\Temp\\ipykernel_23604\\3545717054.py:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  checkpoint = torch.load(\"..\\models\\cifar_model_v1_it19.pt\",weights_only=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"..\\models\\cifar_model_v1_it19.pt\",weights_only=True)\n",
    "mo.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f271e878-fca4-49d0-98c0-fa21dee35c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'cifar_model_v1.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ff59730-3cf5-47eb-bf8b-77c2ef84eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file,'wb') as f_out:\n",
    "    pickle.dump((tf,mo),f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84b8771-e046-4b4e-94aa-b6797789b47a",
   "metadata": {},
   "source": [
    "## EVALUATE MODIFIED RESNET50 PERFORMANCE ON TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e2260-e2d9-42c7-b662-eb0a0508c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(ref_mo,test_dl,ref_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
